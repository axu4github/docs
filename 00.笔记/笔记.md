## 笔记

### 归集程序-VP端替换用户修改:

```bash
1. chown -R ccicall:ccicall /mnt/mfs
2. /ccicall/wildfly10-cesic/standalone/deployments/cesic.war/WEB-INF/conf/log4j2.properties `修改日志存储位置`
3. /ccicall/wildfly10-cesic/standalone/deployments/cesic.war/WEB-INF/conf/log4j.properties `修改日志存储位置`
4. /ccicall/wildfly10-cesic/standalone/deployments/cesic.war/WEB-INF/conf/manage.properties | task.xml `task.xml配置`
5. /ccicall/wildfly10-cesic/standalone/deployments/cesic.war/WEB-INF/conf/spring-engines.xml | `id="engines" sourcedir|user|commonDir|resultFile 配置`
6. chown -R ccicall:ccicall /data/ftp/*
7. sudo -u hdfs hdfs dfs -chown -R ccicall:ccicall /gfbak 
8. /ccicall/wildfly10-cesic/standalone/deployments/cesic.war/WEB-INF/conf/manage.properties | solrcommand | 48 & 50 `solrcommand 文件路径`
9. sudo -u hdfs hdfs dfs -chown -R ccicall:ccicall /user/root/  
12. /ccicall/cesic_src/bin/batch_over.sh `调用路径`
14. /ccicall/wildfly10-cesic/standalone/deployments/cesic.war/WEB-INF/conf/spring-nodes.xml | `user 配置`
15. /ccicall/wildfly10-cesic/standalone/deployments/cesic.war/WEB-INF/conf/cleardata.properties | `identity 配置`
```

### 归集程序编译命令

```bash
归集程序-VP编译命令：`ant -buildfile build-jetty.xml jar`
归集程序-SM编译命令：`ant dep`
```

### TeamViewer

890 938 747

### Mysql和Solr字段对应关系

```xml
<field column="id" name="id" />
<field column="areaOfJob" name="area_of_job" />
<field column="fileName" name="filename" />
<field column="startTime" name="start_time" />
<field column="endTime" name="end_time" />
<field column="duration" name="duration" />
<field column="callNumber" name="callnumber" />
<field column="repNo" name="rep_no" />
<field column="repGroup" name="rep_group" />
<field column="agentNo" name="agent_no" />
<field column="accountCode" name="account_no" />
<field column="repTeam" name="rep_team" />
<field column="callType" name="calltype" />
<field column="voiceCode" name="number_of_record" />
<field column="address" name="region" />
<field column="projectList" name="project_list" />
<field column="satisfaction" name="satisfaction" />
<field column="qualityUserCode" name="qa_no" />
<field column="summaryGroup" name="summarize_group" />
<field column="summaryType" name="summarize_class" />
<field column="summaryProject" name="summarize_project" />
<field column="summaryInfo" name="summarize_content" />
<field column="isQuality" name="is_qa" />
<field column="isLibrary" name="to_warehouse" />
<field column="isStudy" name="to_improvement" />
<field column="active" name="isnormality" />
<field column="busiType" name="type_of_service" />
<field column="statusInfo" name="data_status" />
<field column="statusSecondInfo" name="data_status_2" />
<field column="statusThirdInfo" name="data_status_3" />
<field column="groupManager" name="group_leader" />
<field column="cardNo" name="cust_id" />
<field column="realName" name="cust_name" />
<field column="dealCode" name="audit_no" />
<field column="outPhoneType" name="phone_type" />
<field column="checkType" name="verify_type" />
<field column="repName" name="staff_name" />
<field column="bu_type" name="bu_type" />
<field column="promptInfo" name="rule_prompt" />
<field column="voiceYear" name="years" />
<field column="voiceMonth" name="months" />
<field column="voiceDay" name="days" />
<field column="receiveFile" name="path" />
<field column="filesize" name="filesize" />
<field column="fileunique" name="fileunique" />
<field column="handledfilename" name="handledfilename" />
<field column="plainTextA" name="plaintexta" />
<field column="plainTextB" name="plaintextb" />
<field column="speedResultA" name="speedresulta" />
<field column="speedResultB" name="speedresultb" />
<field column="muteInfo" name="maxblanklen" />
<field column="muteAddress" name="maxstartblankpos" />
<field column="repInterrupt" name="robspeeda" />
<field column="accountInterrupt" name="robspeedb" />
<field column="mapfilepath" name="mapfilepath" />
<field column="mapfilekey" name="mapfilekey" />
<field column="repEmotion" name="emotiona" />
<field column="accountEmotion" name="emotionb" />
```

### Solr 服务器重启

```bash
bin/solr restart -c -m 8g -d smartv/
```

### Solr 数据导入

```bash
java -Durl=http://10.0.3.49:8983/solr/collection1/update -Dtype=text/csv -jar /opt/solr-5.5.1/example/exampledocs/post.jar ${data_file}
```

### Hbase 数据导入

```bash
hbase org.apache.hadoop.hbase.mapreduce.ImportTsv -Dimporttsv.separator=, -Dimporttsv.columns="HBASE_ROW_KEY,cf:area_of_job,cf:filename,cf:start_time,cf:end_time,cf:duration,cf:callnumber,cf:rep_no,cf:rep_group,cf:agent_no,cf:account_no,cf:rep_team,cf:calltype,cf:number_of_record,cf:region,cf:project_list,cf:satisfaction,cf:qa_no,cf:summarize_group,cf:summarize_class,cf:summarize_project,cf:summarize_content,cf:is_qa,cf:to_warehouse,cf:to_improvement,cf:isnormality,cf:type_of_service,cf:data_status,cf:data_status_2,cf:data_status_3,cf:group_leader,cf:cust_id,cf:cust_name,cf:audit_no,cf:phone_type,cf:verify_type,cf:staff_name,cf:bu_type,cf:rule_prompt,cf:years,cf:months,cf:days,cf:path,cf:filesize,cf:fileunique,cf:handledfilename,cf:plaintexta,cf:plaintextb,cf:speedresulta,cf:speedresultb,cf:maxblanklen,cf:maxstartblankpos,cf:robspeeda,cf:robspeedb,cf:mapfilepath,cf:mapfilekey,cf:emotiona,cf:emotionb" smartv hdfs://10.0.3.49:/tmp/1000.csv
```

### Mysql-CSV 表数据导入命令（对应创建的测试索引列）

```bash
# 多行
LOAD DATA LOCAL INFILE '/root/scripts/generate_test_data/datas/20170430.csv' INTO TABLE Voice_000010
FIELDS TERMINATED BY ','
OPTIONALLY ENCLOSED BY '"'
LINES TERMINATED BY '\r\n'
IGNORE 1 LINES
(@6,areaOfJob,fileName,startTime,endTime,duration,callNumber,repNo,repGroup,agentNo,accountCode,repTeam,callType,voiceCode,address,projectList,satisfaction,qualityUserCode,summaryGroup,summaryType,summaryProject,summaryInfo,isQuality,isLibrary,isStudy,active,busiType,statusInfo,statusSecondInfo,statusThirdInfo,groupManager,cardNo,realName,dealCode,outPhoneType,checkType,repName,bu_type,promptInfo,voiceYear,voiceMonth,voiceDay,receiveFile,@1,@2,@3,plainTextA,plainTextB,speedResultA,speedResultB,muteInfo,muteAddress,repInterrupt,accountInterrupt,@4,@5,repEmotion,accountEmotion);

# 单行
LOAD DATA LOCAL INFILE '/root/generate_test_data/data/index.csv_10' INTO TABLE Voice_000001 FIELDS TERMINATED BY ',' OPTIONALLY ENCLOSED BY '"' LINES TERMINATED BY '\r\n' IGNORE 1 LINES (@6,areaOfJob,fileName,startTime,endTime,duration,callNumber,repNo,repGroup,agentNo,accountCode,repTeam,callType,voiceCode,address,projectList,satisfaction,qualityUserCode,summaryGroup,summaryType,summaryProject,summaryInfo,isQuality,isLibrary,isStudy,active,busiType,statusInfo,statusSecondInfo,statusThirdInfo,groupManager,cardNo,realName,dealCode,outPhoneType,checkType,repName,bu_type,promptInfo,voiceYear,voiceMonth,voiceDay,receiveFile,@1,@2,@3,plainTextA,plainTextB,speedResultA,speedResultB,muteInfo,muteAddress,repInterrupt,accountInterrupt,@4,@5,repEmotion,accountEmotion);
```

### Hive-CSV 表创建（对应创建的测试索引列）

```bash
CREATE TABLE IF NOT EXISTS smartv_hive_main (
    key string,
    area_of_job string,
    file_name string,
    start_time string,
    update_time string,
    duration string,
    call_number string,
    rep_no string,
    rep_group string,
    agent_no string,
    account_no string,
    rep_team string,
    call_type string,
    record_no string,
    region string,
    project_list string,
    satisfaction string,
    qa_no string,
    summarize_group string,
    summarize_class string,
    summarize_project string,
    summarize_content string,
    is_qa string,
    to_warehouse string,
    to_improvement string,
    is_normality string,
    type_of_service string,
    data_status string,
    data_status_2 string,
    data_status_3 string,
    group_leader string,
    cust_id string,
    cust_name string,
    audit_no string,
    phone_type string,
    verify_type string,
    staff_name string,
    bu_type string,
    rule_prompt string,
    years string,
    months string,
    days string,
    path string,
    file_size string,
    file_unique string,
    handled_file_name string,
    plain_text_a string,
    plain_text_b string,
    speed_result_a string,
    speed_result_b string,
    max_blank_len string,
    max_start_blank_pos string,
    rob_speed_a string,
    rob_speed_b string,
    map_file_path string,
    map_file_key string,
    emotiona string,
    emotionb string,
    blank_info string,
    similarity string
)
ROW FORMAT SERDE 'org.apache.hadoop.hive.serde2.OpenCSVSerde'
STORED AS TEXTFILE
TBLPROPERTIES ("skip.header.line.count"="1");
```

### 加载CSV数据

```bash
LOAD DATA LOCAL INPATH '/root/scripts/generate_test_data/datas/20170430.csv' INTO TABLE smartv_hive_main;
```

