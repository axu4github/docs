## 笔记

### 归集程序-VP端替换用户修改:

```bash
1. chown -R ccicall:ccicall /mnt/mfs
2. /ccicall/wildfly10-cesic/standalone/deployments/cesic.war/WEB-INF/conf/log4j2.properties `修改日志存储位置`
3. /ccicall/wildfly10-cesic/standalone/deployments/cesic.war/WEB-INF/conf/log4j.properties `修改日志存储位置`
4. /ccicall/wildfly10-cesic/standalone/deployments/cesic.war/WEB-INF/conf/manage.properties | task.xml `task.xml配置`
5. /ccicall/wildfly10-cesic/standalone/deployments/cesic.war/WEB-INF/conf/spring-engines.xml | `id="engines" sourcedir|user|commonDir|resultFile 配置`
6. chown -R ccicall:ccicall /data/ftp/*
7. sudo -u hdfs hdfs dfs -chown -R ccicall:ccicall /gfbak
8. /ccicall/wildfly10-cesic/standalone/deployments/cesic.war/WEB-INF/conf/manage.properties | solrcommand | 48 & 50 `solrcommand 文件路径`
9. sudo -u hdfs hdfs dfs -chown -R ccicall:ccicall /user/root/  
12. /ccicall/cesic_src/bin/batch_over.sh `调用路径`
14. /ccicall/wildfly10-cesic/standalone/deployments/cesic.war/WEB-INF/conf/spring-nodes.xml | `user 配置`
15. /ccicall/wildfly10-cesic/standalone/deployments/cesic.war/WEB-INF/conf/cleardata.properties | `identity 配置`
```

### 归集程序编译命令

```bash
归集程序-VP编译命令：`ant -buildfile build-jetty.xml jar`
归集程序-SM编译命令：`ant dep`
```

### Mysql和Solr字段对应关系

```xml
<field column="id" name="id" />
<field column="areaOfJob" name="area_of_job" />
<field column="fileName" name="filename" />
<field column="startTime" name="start_time" />
<field column="endTime" name="end_time" />
<field column="duration" name="duration" />
<field column="callNumber" name="callnumber" />
<field column="repNo" name="rep_no" />
<field column="repGroup" name="rep_group" />
<field column="agentNo" name="agent_no" />
<field column="accountCode" name="account_no" />
<field column="repTeam" name="rep_team" />
<field column="callType" name="calltype" />
<field column="voiceCode" name="number_of_record" />
<field column="address" name="region" />
<field column="projectList" name="project_list" />
<field column="satisfaction" name="satisfaction" />
<field column="qualityUserCode" name="qa_no" />
<field column="summaryGroup" name="summarize_group" />
<field column="summaryType" name="summarize_class" />
<field column="summaryProject" name="summarize_project" />
<field column="summaryInfo" name="summarize_content" />
<field column="isQuality" name="is_qa" />
<field column="isLibrary" name="to_warehouse" />
<field column="isStudy" name="to_improvement" />
<field column="active" name="isnormality" />
<field column="busiType" name="type_of_service" />
<field column="statusInfo" name="data_status" />
<field column="statusSecondInfo" name="data_status_2" />
<field column="statusThirdInfo" name="data_status_3" />
<field column="groupManager" name="group_leader" />
<field column="cardNo" name="cust_id" />
<field column="realName" name="cust_name" />
<field column="dealCode" name="audit_no" />
<field column="outPhoneType" name="phone_type" />
<field column="checkType" name="verify_type" />
<field column="repName" name="staff_name" />
<field column="bu_type" name="bu_type" />
<field column="promptInfo" name="rule_prompt" />
<field column="voiceYear" name="years" />
<field column="voiceMonth" name="months" />
<field column="voiceDay" name="days" />
<field column="receiveFile" name="path" />
<field column="filesize" name="filesize" />
<field column="fileunique" name="fileunique" />
<field column="handledfilename" name="handledfilename" />
<field column="plainTextA" name="plaintexta" />
<field column="plainTextB" name="plaintextb" />
<field column="speedResultA" name="speedresulta" />
<field column="speedResultB" name="speedresultb" />
<field column="muteInfo" name="maxblanklen" />
<field column="muteAddress" name="maxstartblankpos" />
<field column="repInterrupt" name="robspeeda" />
<field column="accountInterrupt" name="robspeedb" />
<field column="mapfilepath" name="mapfilepath" />
<field column="mapfilekey" name="mapfilekey" />
<field column="repEmotion" name="emotiona" />
<field column="accountEmotion" name="emotionb" />
```

### Mysql权限

```bash
mysql> GRANT ALL PRIVILEGES ON *.* TO 'root'@'%' WITH GRANT OPTION;
mysql> flush privileges;hgfds
```

### Solr 服务器重启

```bash
bin/solr restart -c -m 8g -d smartv/
```

### Solr 数据导入

```bash
java -Durl=http://10.0.3.49:8983/solr/collection1/update -Dtype=text/csv -jar /opt/solr-5.5.1/example/exampledocs/post.jar ${data_file}
```

### Hbase

#### Hbase 数据导入

```bash
hbase org.apache.hadoop.hbase.mapreduce.ImportTsv -Dimporttsv.separator=, -Dimporttsv.columns="HBASE_ROW_KEY,cf:area_of_job,cf:filename,cf:start_time,cf:end_time,cf:duration,cf:callnumber,cf:rep_no,cf:rep_group,cf:agent_no,cf:account_no,cf:rep_team,cf:calltype,cf:number_of_record,cf:region,cf:project_list,cf:satisfaction,cf:qa_no,cf:summarize_group,cf:summarize_class,cf:summarize_project,cf:summarize_content,cf:is_qa,cf:to_warehouse,cf:to_improvement,cf:isnormality,cf:type_of_service,cf:data_status,cf:data_status_2,cf:data_status_3,cf:group_leader,cf:cust_id,cf:cust_name,cf:audit_no,cf:phone_type,cf:verify_type,cf:staff_name,cf:bu_type,cf:rule_prompt,cf:years,cf:months,cf:days,cf:path,cf:filesize,cf:fileunique,cf:handledfilename,cf:plaintexta,cf:plaintextb,cf:speedresulta,cf:speedresultb,cf:maxblanklen,cf:maxstartblankpos,cf:robspeeda,cf:robspeedb,cf:mapfilepath,cf:mapfilekey,cf:emotiona,cf:emotionb" smartv hdfs://10.0.3.49:/tmp/1000.csv
```

#### Hbase Shell 操作命令集

```bash
# 进入 hbase shell
> hbase shell
17/10/12 14:26:35 WARN conf.Configuration: hadoop.native.lib is deprecated. Instead, use io.native.lib.available
HBase Shell; enter 'help<RETURN>' for list of supported commands.
Type "exit<RETURN>" to leave the HBase Shell
Version 0.94.6-cdh4.5.0, rUnknown, Wed Nov 20 15:46:19 PST 2013

# 查看所有表
hbase> list
TABLE                                                                                                             
smartv                                                                                                            
smartv_black_list                                                                                                 
smartv_cache                                                                                                      
smartv_check_detail                                                                                               
smartv_check_history                                                                                              
smartv_new                                                                                                        
smartv_property                                                                                                   
waveform                                                                                                          
8 row(s) in 0.5830 seconds

# 查看某张表前n条记录
hbase> scan 'smartv', { LIMIT=>1 }
ROW                           COLUMN+CELL      
[...]
1 row(s) in 0.2140 seconds

```

### Mysql-CSV 表数据导入命令（对应创建的测试索引列）

```bash
# 多行
mysql> LOAD DATA LOCAL INFILE '/root/scripts/generate_test_data/datas/20170430.csv' INTO TABLE Voice_000010
FIELDS TERMINATED BY ','
OPTIONALLY ENCLOSED BY '"'
LINES TERMINATED BY '\r\n'
IGNORE 1 LINES
(textFileName,areaOfJob,fileName,startTime,endTime,duration,callNumber,repNo,repGroup,agentNo,accountCode,repTeam,callType,voiceCode,address,projectList,satisfaction,qualityUserCode,summaryGroup,summaryType,summaryProject,summaryInfo,isQuality,isLibrary,isStudy,active,busiType,statusInfo,statusSecondInfo,statusThirdInfo,groupManager,cardNo,realName,dealCode,outPhoneType,checkType,repName,bu_type,promptInfo,voiceYear,voiceMonth,voiceDay,receiveFile,@1,@2,@3,plainTextA,plainTextB,speedResultA,speedResultB,muteInfo,muteAddress,repInterrupt,accountInterrupt,@4,@5,repEmotion,accountEmotion);

# 单行
mysql> LOAD DATA LOCAL INFILE '/root/generate_test_data/data/index.csv_10' INTO TABLE Voice_000001 FIELDS TERMINATED BY ',' OPTIONALLY ENCLOSED BY '"' LINES TERMINATED BY '\r\n' IGNORE 1 LINES (textFileName,areaOfJob,fileName,startTime,endTime,duration,callNumber,repNo,repGroup,agentNo,accountCode,repTeam,callType,voiceCode,address,projectList,satisfaction,qualityUserCode,summaryGroup,summaryType,summaryProject,summaryInfo,isQuality,isLibrary,isStudy,active,busiType,statusInfo,statusSecondInfo,statusThirdInfo,groupManager,cardNo,realName,dealCode,outPhoneType,checkType,repName,bu_type,promptInfo,voiceYear,voiceMonth,voiceDay,receiveFile,@1,@2,@3,plainTextA,plainTextB,speedResultA,speedResultB,muteInfo,muteAddress,repInterrupt,accountInterrupt,@4,@5,repEmotion,accountEmotion);
```

### Hive-CSV 表创建（对应创建的测试索引列）

```bash
hive> CREATE TABLE IF NOT EXISTS smartv_hive_main (
    key string,
    area_of_job string,
    file_name string,
    start_time string,
    update_time string,
    duration string,
    call_number string,
    rep_no string,
    rep_group string,
    agent_no string,
    account_no string,
    rep_team string,
    call_type string,
    record_no string,
    region string,
    project_list string,
    satisfaction string,
    qa_no string,
    summarize_group string,
    summarize_class string,
    summarize_project string,
    summarize_content string,
    is_qa string,
    to_warehouse string,
    to_improvement string,
    is_normality string,
    type_of_service string,
    data_status string,
    data_status_2 string,
    data_status_3 string,
    group_leader string,
    cust_id string,
    cust_name string,
    audit_no string,
    phone_type string,
    verify_type string,
    staff_name string,
    bu_type string,
    rule_prompt string,
    years string,
    months string,
    days string,
    path string,
    file_size string,
    file_unique string,
    handled_file_name string,
    plain_text_a string,
    plain_text_b string,
    speed_result_a string,
    speed_result_b string,
    max_blank_len string,
    max_start_blank_pos string,
    rob_speed_a string,
    rob_speed_b string,
    map_file_path string,
    map_file_key string,
    emotiona string,
    emotionb string,
    blank_info string,
    similarity string
)
ROW FORMAT SERDE 'org.apache.hadoop.hive.serde2.OpenCSVSerde'
STORED AS TEXTFILE
TBLPROPERTIES ("skip.header.line.count"="1");
```

### 加载CSV数据

```bash
hive> LOAD DATA LOCAL INPATH '/root/scripts/generate_test_data/datas/20170430.csv' INTO TABLE smartv_hive_main;
```

### Hive数据导入Hbase

```bash
# 创建Hive外部表
hive> CREATE EXTERNAL TABLE IF NOT EXISTS smartv_hbase_main (
    key string,
    area_of_job string,
    file_name string,
    start_time string,
    update_time string,
    duration string,
    call_number string,
    rep_no string,
    rep_group string,
    agent_no string,
    account_no string,
    rep_team string,
    call_type string,
    record_no string,
    region string,
    project_list string,
    satisfaction string,
    qa_no string,
    summarize_group string,
    summarize_class string,
    summarize_project string,
    summarize_content string,
    is_qa string,
    to_warehouse string,
    to_improvement string,
    is_normality string,
    type_of_service string,
    data_status string,
    data_status_2 string,
    data_status_3 string,
    group_leader string,
    cust_id string,
    cust_name string,
    audit_no string,
    phone_type string,
    verify_type string,
    staff_name string,
    bu_type string,
    rule_prompt string,
    years string,
    months string,
    days string,
    path string,
    file_size string,
    file_unique string,
    handled_file_name string,
    plain_text_a string,
    plain_text_b string,
    speed_result_a string,
    speed_result_b string,
    max_blank_len string,
    max_start_blank_pos string,
    rob_speed_a string,
    rob_speed_b string,
    map_file_path string,
    map_file_key string,
    emotiona string,
    emotionb string,
    blank_info string,
    similarity string
)
STORED BY 'org.apache.hadoop.hive.hbase.HBaseStorageHandler'
WITH SERDEPROPERTIES ("hbase.columns.mapping" = ":key,cf:area_of_job,cf:file_name,cf:start_time,cf:update_time,cf:duration,cf:call_number,cf:rep_no,cf:rep_group,cf:agent_no,cf:account_no,cf:rep_team,cf:call_type,cf:record_no,cf:region,cf:project_list,cf:satisfaction,cf:qa_no,cf:summarize_group,cf:summarize_class,cf:summarize_project,cf:summarize_content,cf:is_qa,cf:to_warehouse,cf:to_improvement,cf:is_normality,cf:type_of_service,cf:data_status,cf:data_status_2,cf:data_status_3,cf:group_leader,cf:cust_id,cf:cust_name,cf:audit_no,cf:phone_type,cf:verify_type,cf:staff_name,cf:bu_type,cf:rule_prompt,cf:years,cf:months,cf:days,cf:path,cf:file_size,cf:file_unique,cf:handled_file_name,cf:plain_text_a,cf:plain_text_b,cf:speed_result_a,cf:speed_result_b,cf:max_blank_len,cf:max_start_blank_pos,cf:rob_speed_a,cf:rob_speed_b,cf:map_file_path,cf:map_file_key,cf:emotiona,cf:emotionb,cf:blank_info,cf:similarity")
TBLPROPERTIES("hbase.table.name" = "smartv");

# 导入数据
hive> INSERT INTO TABLE smartv_hbase_main SELECT * FROM smartv_hive_main;
```

### Sublime换行

替换：`command + option + f`
换行：`command + shift + enter`

### wget 下载 repo 指定安装包

```bash
# 参数说明：
# -c 短点续传
# -r 递归下载
# -np 递归下载不搜索上层目录
# -k 将绝对链接转为相对链接，下载整个站点后脱机浏览网页，最好加上这个参数
# -L 递归时不进入其它主机
# -p 下载网页所需的所有文件，如图片等
> nohup wget -c -r -np -k -L -p https://archive.cloudera.com/cm5/redhat/6/x86_64/cm/5.6.0/ &
[...]

# 现在完成后会出现一堆 "index.html" 的垃圾文件
> find ./ -name "index.html*"
./index.html?C=S;O=A
./index.html?C=N;O=A
./index.html?C=S;O=D
./index.html?C=D;O=A
./index.html?C=D;O=D
./index.html?C=M;O=A
./index.html
./SRPMS/index.html?C=S;O=As
./SRPMS/index.html?C=N;O=A
./SRPMS/index.html?C=S;O=D
./SRPMS/index.html?C=D;O=A
./SRPMS/repodata/index.html?C=S;O=A
./SRPMS/repodata/index.html?C=N;O=A
[...]

# 删除这些垃圾文件
> rm -rf `find ./ -name "index.html*"`

# 检查
> find ./ -name "index.html*"
```
